# The Human Data Digital Toolkit (HDDT) #

The HDDT constitutes a new approach to the study of Past Human Lives (PHL) by the application of Information Science and Data Science techniques deployed to the study of ordered Evidence Based Prosopographical (EBP) information on Past Human Lives.
The HDDT enables researchers to create a data pipeline by integrating multiple archival datasets into one SQLite database. The resulting combined data can then be cleaned, viewed, analysed, and visualised by using compatible open-source software packages (Jupyter Notebooks and Gephi). The HDDT is a process for using SQLite, Python Notebooks and Gephi which is designed to enable historical ordered data to be surveyed, much as an archaeologist might use a variety of technologies to survey a territorial site of historical interest. The HDDT is not a tool for finding individual or even several items in an archive.

Exponential population growth in the eighteenth and nineteenth centuries presents to researchers archival data at volume but that data comes with significant data handling and management challenges. Fortunately, a prolonged cultural, disciplined, and extensive interest in collecting, cataloguing, and preserving historical artefacts and manuscripts, was pursued by collectors at the time, and archivists later. This has resulted in the accessibility of a huge quantity of ordered and organised historical data, especially of manuscripts and print. This offers to the researcher an opportunity to study in terconnected communities and whole societies ‘en masse’. 

The historical archives of the nineteenth century are often very large (and are immense when viewed collectively), they are too big to be surveyed by the naked eye or even by using 'office' based technologies. Nonetheless they offer rich sources of ordered data sets (organised through metadata, catalogued and frequently cross-referenced to each other - record to record and collection to collection). Furthermore, archived nineteenth century manuscripts frequently include ‘within themselves’ ordered data items such as surveys, lists and indexes. These are a rich source of historical data. Data science is now capable of handling ordered historical data on large scales, it is time to devise a way for EBP data to be studied in and of itself, free of narratology, by using open-source technologies capable of embracing mass data. 

The HDDT provides a satisfactory way of studying mass data across multiple archives. With the HDDT there is no need to limit the focus of research to only the rich, the powerful, the clever or the famous. The HDDT is designed to include everyone on every list, in every collection, in every catalogue, in every archive.

This repository consists of a denonstration of the application of the HDDT. The 3000 people active in the Centres for the Emergence of the Discipline of Anthropology in Britain (The CEDA) 1830 – 1870, and the 600 Quakers amongst them are the test case explored in this project. The larger, and smaller, communities are analysed year by year both statically and dynamically, focussing on the bigraph relationships of the larger community to the locations, occupations, societies and clubs they belonged to, and amongst the Quaker community – their family relationships.

Begin by reading the Introduction and then go on to the Methodology.

[INTRODUCTION](https://github.com/KelvinBeerJones/jnb_hddt_intro/blob/main/jnb_hddt_intro.ipynb "Introduction")

[METHODOLOGY](https://github.com/KelvinBeerJones/ceda_database_views/blob/main/jnb_ceda_database_views.ipynb "Methodology")

